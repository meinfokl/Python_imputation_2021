{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator training\n",
      "M: 10 dim: 20 cube size: 100000000000000000000 real size: 10000  train_size: 20000 batch count: 20 test_size: 300 mode: uniform_random\n",
      "[1.2535434, 0.47324732]\n",
      "[1.6205341, 0.640214]\n",
      "[1.1738085, 0.5827083]\n",
      "[1.1758572, 0.45314533]\n",
      "[1.2753623, 0.41084108]\n",
      "[1.1041732, 0.45684567]\n",
      "[0.9766787, 0.55860585]\n",
      "[1.0367733, 0.6281628]\n",
      "[1.0403057, 0.64641464]\n",
      "[0.94023204, 0.6231123]\n",
      "[0.86786014, 0.5773577]\n",
      "[0.90536785, 0.510001]\n",
      "[0.9220582, 0.49524954]\n",
      "[0.8545604, 0.5509551]\n",
      "[0.8134502, 0.63451344]\n",
      "[0.8536915, 0.6560156]\n",
      "[0.85833174, 0.65941596]\n",
      "[0.8205815, 0.64936495]\n",
      "[0.7959021, 0.62951297]\n",
      "[0.8118389, 0.6141114]\n",
      "accuracy= 0.34 0.10222222222222223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from plot_keras_history import plot_history\n",
    "import random \n",
    "import math\n",
    "\n",
    "def define_discriminator(n_inputs):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8 *n_inputs, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(8 *n_inputs, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "def train_discrimantor_batch(discriminator,DD, M, N2, B):\n",
    "\n",
    "    N1 = int(N2/3)\n",
    "    \n",
    "    for _ in range(B):\n",
    "        \n",
    "        x_real = np.zeros((N1,data_dim))\n",
    "        y_real = np.zeros((N1,1))\n",
    "\n",
    "        for n in range(N1):\n",
    "            i = random.randint(0,N-1)\n",
    "            for j in range(data_dim):\n",
    "                x_real[n,j] = DArray[i][j] \n",
    "            y_real[n,0] = 1\n",
    "\n",
    "\n",
    "        x_fake = np.zeros((N1,data_dim))\n",
    "        y_fake = np.zeros((N1,1))\n",
    "\n",
    "        for n in range(N1):\n",
    "            fnd = 1\n",
    "            while fnd == 1:\n",
    "                x = []\n",
    "                for j in range(data_dim):\n",
    "                    x.append(random.randint(0,M-1))\n",
    "                if tuple(x) not in DD.keys():\n",
    "                    fnd = 0\n",
    "            for j in range(data_dim):\n",
    "                x_fake[n,j] = x[j]             \n",
    "            y_fake[n,0] = 0\n",
    "\n",
    "        x_train = np.zeros((3*N1, data_dim))\n",
    "        y_train = np.zeros((3*N1, 1))\n",
    "\n",
    "        for n in range(N1):\n",
    "            for j in range(data_dim):\n",
    "                x_train[3*n,j] = x_real[n,j]\n",
    "                x_train[3*n+1,j] = x_fake[n,j]\n",
    "                x_train[3*n+2,j] = random.random()\n",
    "            y_train [3*n,0] = 1\n",
    "            y_train [3*n + 1,0] = 0\n",
    "            y_train [3*n + 2,0] = 0\n",
    "\n",
    "\n",
    "        r = discriminator.train_on_batch(x_train, y_train)\n",
    "        print (r)\n",
    "\n",
    "\n",
    "def train_discrimantor(discriminator,DD, M, N2, E):\n",
    "\n",
    "    N1 = int(N2/3)\n",
    "        \n",
    "    x_real = np.zeros((N1,data_dim))\n",
    "    y_real = np.zeros((N1,1))\n",
    "    \n",
    "    for n in range(N1):\n",
    "        i = random.randint(0,N-1)\n",
    "        for j in range(data_dim):\n",
    "            x_real[n,j] = DArray[i][j] \n",
    "        y_real[n,0] = 1\n",
    "\n",
    "\n",
    "    x_fake = np.zeros((N1,data_dim))\n",
    "    y_fake = np.zeros((N1,1))\n",
    "\n",
    "    for n in range(N1):\n",
    "        fnd = 1\n",
    "        while fnd == 1:\n",
    "            x = []\n",
    "            for j in range(data_dim):\n",
    "                x.append(random.randint(0,M-1))\n",
    "            if tuple(x) not in DD.keys():\n",
    "                fnd = 0\n",
    "        for j in range(data_dim):\n",
    "            x_fake[n,j] = x[j]             \n",
    "        y_fake[n,0] = 0\n",
    "\n",
    "    x_train = np.zeros((3*N1, data_dim))\n",
    "    y_train = np.zeros((3*N1, 1))\n",
    "    \n",
    "    for n in range(N1):\n",
    "        for j in range(data_dim):\n",
    "            x_train[3*n,j] = x_real[n,j]\n",
    "            x_train[3*n+1,j] = x_fake[n,j]\n",
    "            x_train[3*n+2,j] = random.random()\n",
    "        y_train [3*n,0] = 1\n",
    "        y_train [3*n + 1,0] = 0\n",
    "        y_train [3*n + 2,0] = 0\n",
    "            \n",
    "\n",
    "    r = discriminator.fit(x_train, y_train,epochs=E,verbose = 0)\n",
    "    plot_history(r.history)\n",
    "\n",
    "def prepare_data(N, data_dim, M ):    \n",
    "    \n",
    "    DA = np.zeros((N, data_dim))\n",
    "    DD = dict()\n",
    "    for n in range(N):\n",
    "        for j in range(data_dim):\n",
    "            DA[n,j] = random.randint(0,M-1)\n",
    "        DD[tuple(DA[n,:]) ] = 1\n",
    "    return (DA,DD)\n",
    "\n",
    "def prepare_data_2(N, data_dim, M ):    \n",
    "    M = 4\n",
    "    DA = np.zeros((N, data_dim))\n",
    "    DD = dict()\n",
    "    for n in range(N):\n",
    "        for j in range(data_dim):\n",
    "            DA[n,j] = random.randint(0,M-1)\n",
    "        DD[tuple(DA[n,:]) ] = 1\n",
    "        \n",
    "    return (DA,DD)\n",
    "\n",
    "\n",
    "def test_discriminator(discriminator, data_dim, DD, DA,  M, N1 ):\n",
    "    \n",
    "    db  = 0\n",
    "    dbp = 0\n",
    "    for _ in range(3):\n",
    "        x_test = np.zeros((N1, data_dim))\n",
    "        y_test = np.zeros((N1, 1))\n",
    "    \n",
    "        for n in range(N1):\n",
    "            if random.random() < 0.1:\n",
    "                m = random.randint(0, DA.shape[0]-1)\n",
    "                for j in range(data_dim):\n",
    "                    x_test[n,j] = DA[m,j]\n",
    "                y_test[n,0] = 1\n",
    "                dbp = dbp + 1\n",
    "            else:\n",
    "                for j in range(data_dim):\n",
    "                    x_test[n,j] = random.randint(0,M-1)\n",
    "                if tuple(x_test[n,:]) in DD.keys():\n",
    "                    y_test[n,0] = 1\n",
    "                    dbp = dbp + 1\n",
    "                else:\n",
    "                    y_test[n,0] = 0\n",
    "\n",
    "        y_pred = discriminator.predict(x_test)\n",
    "\n",
    "        for n in range(N1):\n",
    "            if abs(y_pred[n]-y_test[n]) < .5:\n",
    "                db = db + 1\n",
    "           \n",
    "    print (\"accuracy=\", db / (3*N1), dbp / (3*N1) )\n",
    "    \n",
    "    \n",
    "            \n",
    "data_dim = 20  # dimensions\n",
    "M = 10    # values\n",
    "N = 10000    # real size \n",
    "N2 = 20000  # train size\n",
    "E = 20  # Epochs\n",
    "B = 20  # batch \n",
    "N3 = 300   # test size\n",
    "\n",
    "(DArray, DDict)  = prepare_data(N, data_dim, M)\n",
    "print (\"Discriminator training\")\n",
    "\n",
    "\n",
    "discriminator = define_discriminator(data_dim)\n",
    "\n",
    "#print (\"M:\",M,\"dim:\",data_dim, \"cube size:\", M**data_dim, \"real size:\",N, \" train_size:\", N2,\"epochs:\", E, \"test_size:\", N3, \"mode: uniform_random\")\n",
    "#train_discrimantor(discriminator, DDict,  M, N2, E)\n",
    "\n",
    "print (\"M:\",M,\"dim:\",data_dim, \"cube size:\", M**data_dim, \"real size:\",N, \" train_size:\", N2,\"batch count:\", B, \"test_size:\", N3, \"mode: uniform_random\")\n",
    "train_discrimantor_batch(discriminator, DDict,  M, N2, B)\n",
    "\n",
    "test_discriminator(discriminator, data_dim, DDict, DArray, M, N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
